{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author: Etienne Bonnassieux\n",
    "## Comments, questions? Contact etienne.bonnassieux@obspm.fr\n",
    "\n",
    "# **I. Prerequisites**\n",
    "\n",
    "In this jupyter notebook, we will learn how to install & run DDFacet on a LOFAR dataset. For this, you must first have the following installed (non-exhaustive list, I probably forgot at least one thing):\n",
    "\n",
    "- the KERN suite http://kernsuite.info/installation/\n",
    "- ddfacet - sudo apt-get install ddfacet; pip install ephem\n",
    "- dysco (if using a LOFAR dataset) - sudo apt-get install dysco\n",
    "- LOFAR softs, which include NDPPP - sudo apt-get install lofar\n",
    "\n",
    "Note that all the installs recommended here only work after installing KERN. If you don't want to use KERN, that is fine! Just be prepared for a good week of tears and sorrow. Note that KERN also comes with a lot of other useful radio-astro tools; I personally recommend tigger as an image viewer (takes a while to get used to but has some very useful functions) and pybdsf if you wish to get deeper than this tutorial in interferometric imaging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **II. Introduction**\n",
    "\n",
    "\n",
    "The aim of this tutorial is to calibrate & image a small LOFAR dataset. Here is our order of operations:\n",
    "- Acquire the dataset (1.3GB disk space required)\n",
    "- Calibrate the dataset using NDPPP\n",
    "- Inspect the gain solutions\n",
    "- Image the calibrated data\n",
    "- Discuss self-calibration\n",
    "\n",
    "To acquire the dataset, you would normally stage your files through the LOFAR Long-Term Archive (LTA). Here, because we want to work on a small dataset (30min), we will simply download it through the following link:  https://upload.obspm.fr/get?k=BMZQa9VRhz9U2p872MA\n",
    "\n",
    "However, should you wish to acquire LTA data in the future, here are the main steps to perform.\n",
    "1. Get an LTA account. This is often the most difficult part.\n",
    "2. Find your dataset on the LTA interface. Also non-trivial.\n",
    "3. Stage your dataset. \"Staging\" means that your dataset, which is usually stored on magnetic tapes to my knowledge, is physically moved to a location where you can access it online. You will receive an automatic notification telling you that your data is being staged, and another once it's successfully staged. You can then download it following the instructions given in your email and at the following webpage: https://www.astron.nl/lofarwiki/doku.php?id=public:lta_howto\n",
    "4. Once your data is staged, you can untar the file. If in doubt, you can always use M.C. Toribio's untar script to untar all the files in a single command. This script can be found here: https://github.com/ebonnassieux/Scripts/blob/master/untar.py\n",
    "5. Finally, because there can be issues with MS locks, it is often worth removing them altogether before doing any work on them. This can be done with a bash command from the directory where your MS are stored: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '*MS/*lock': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "mkdir DATA\n",
    "mv L242400_SB095_uv.dppp.4h-4.5h.MS.tar.gz DATA\n",
    "cd DATA\n",
    "tar -xvf L242400_SB095_uv.dppp.4h-4.5h.MS.tar.gz\n",
    "rm *MS/*lock\n",
    "cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have thus created a DATA directory where we've moved our downloaded dataset, untarred it, removed the lock, and then we returned to our working directory. We can thus start the calibration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **III. Calibration**\n",
    "\n",
    "In this tutorial, we will calibrate our data using the New Default Preprocessing Pipeline, or NDPPP. This is the standard tool used for calibration in PreFACTOR. Information on NDPPP can be found on the LOFAR documentation wiki: https://www.astron.nl/lofarwiki/doku.php?id=public:user_software:documentation:ndppp\n",
    "\n",
    "Note that all the steps outlined here can be found in the LOFAR imaging cookbook, which is a very complete resource. If you run into a problem, which is likely to occur, someone else probably had the same issue before you: if so, the solution can likely be found in the cookbook. The most up-to-date version can be found here: https://www.astron.nl/radio-observatory/lofar/lofar-imaging-cookbook\n",
    "\n",
    "A pdf version can also be found here: https://www.astron.nl/lofarwiki/lib/exe/fetch.php?media=public:lofar_imaging_cookbook_v18.pdf\n",
    "\n",
    "To calibrate, we first need to acquire a model of the sky visible to our instrument during our pointing. There are a few ways to do this - the most reliable automated method is to extrapolate source positions and fluxes from other sky surveys. As a very basic starting point, however, one can use the Global Sky Model tool, gsm. Unfortunately it's not as easy as I had hoped to install...so instead, copy the following cell in a file which we will call tutorial.skymodel :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "format = Name, Type, Ra, Dec, I, Q, U, V, MajorAxis, MinorAxis, Orientation, ReferenceFrequency='1.17577e+08', SpectralIndex='[]'\n",
    "\n",
    "IMAGES/sb035VLApybdsmModel.firstcal.ssd1.int.restored_w0_i3_s1_g1, GAUSSIAN, 14:11:20.589732, +52.12.9.390453, 3.532e+01, 0.0, 0.0, 0.0, 1.80160e+00, 7.85124e-01, 1.57039e+02, 1.17577e+08, [-0.8]\n",
    "IMAGES/sb035VLApybdsmModel.firstcal.ssd1.int.restored_w0_i3_s2_g2, GAUSSIAN, 14:11:20.717747, +52.12.7.867312, 2.395e+01, 0.0, 0.0, 0.0, 5.71713e-01, 3.66106e-01, 3.06168e+00, 1.17577e+08, [-0.8]\n",
    "IMAGES/sb035VLApybdsmModel.firstcal.ssd1.int.restored_w0_i3_s0_g0, GAUSSIAN, 14:11:20.432337, +52.12.11.148637, 1.928e+01, 0.0, 0.0, 0.0, 7.40989e-01, 0.00000e+00, 1.33188e+02, 1.17577e+08, [-0.8]\n",
    "IMAGES/sb035VLApybdsmModel.firstcal.ssd1.int.restored_w0_i3_s3_g3, GAUSSIAN, 14:11:20.799233, +52.12.6.145349, 1.926e+01, 0.0, 0.0, 0.0, 3.22666e+00, 9.18858e-01, 6.44905e+01, 1.17577e+08, [-0.8]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a model consisting of 4 clustered Gaussian, which together model 3C295, the brightest source by far in our field. It's not the best model, not by far - but it's the best I had to hand in this format, considering that gsm seems to be horribly broken now. Better practice would be to get a list of NVSS sources and use that as a model - but 3C295 is a double source at Dutch LOFAR resolutions, and dominates the field, so I am using this model in our example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We thus have a starting sky model in the form of a list of Gaussians and points. However, before we can use NDPPP, we must perform one more step: turn this into a \"modeldb\" (model database). This is done through the following command in bash:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "makesourcedb in=tutorial.skymodel out=DATA/L242400_SB095_uv.dppp.4h-4.5h.MS.sky format='<'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obnoxiously, KERN's version of makesourcedb doesn't seem to work. Instead, just stick the sky folder inside the measurement set and be done with it - it was made with a working version of makesourcedb. Such as the dark magicks of LOFAR software."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create the NDPPP parset we wish to use, simply copy and paste the contents of the next cell in a file we will call \"ndppp.calibration.parset\" :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msin  = DATA/L242400_SB095_uv.dppp.4h-4.5h.MS\n",
    "msout = DATA/L242400_SB095_uv.dppp.4h-4.5h.MS\n",
    "msout.datacolumn = CORRECTED_DATA\n",
    "#msin.baseline=^CS*&  # ^ is the Not operator.\n",
    "msout.overwrite  = true\n",
    "\n",
    "# define the steps we use:\n",
    "# gaincal calibrates\n",
    "steps = [gaincal]\n",
    "\n",
    "# if you wanted to average your dataset\n",
    "#steps=[averager]\n",
    "#averager.freqstep=8\n",
    "#averager.timestep=10\n",
    "\n",
    "gaincal.baseline       = [CR]*&&              # flag international stations\n",
    "gaincal.caltype        = diagonal\n",
    "gaincal.applysolution  = true\n",
    "gaincal.solint         = 8\n",
    "gaincal.nchan          = 4\n",
    "gaincal.maxiter        = 800\n",
    "gaincal.sourcedb       = DATA/L242400_SB095_uv.dppp.4h-4.5h.MS/sky\n",
    "gaincal.parmdb         =\n",
    "gaincal.operation      = replace\n",
    "gaincal.usebeammodel   = true\n",
    "gaincal.usechannelfreq = false\n",
    "gaincal.beammode       = default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we're nearly done - all that's left is to actually run NDPPP! In our case, because we specify msin and msout in the parset, this is done by copying the following command into a bash terminal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NDPPP ndppp.calibration.parset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simply wait for NDPPP to do its thing. In the meantime, it pays to look at what NDPPP is telling you - almost 100% of the time, if there's a problem with your calibration, your solver will tell you! Somewhere under the deluge of information it outputs, anyway..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# **IV. Imaging**\n",
    "\n",
    "Finally, we get to the meat of the matter: imaging using DDFacet. First, should you want to have a standalone install of DDFacet (and its companion calibration software, killMS - here, we used NDPPP to do what killMS would), go to the following two git repos:\n",
    "\n",
    "* https://github.com/saopicc/DDFacet\n",
    "* https://github.com/saopicc/killMS\n",
    "\n",
    "and follow the instructions there. There are usually a host of problems with that sort of installation, as with all radio-astronomy software. Note that you can find the best \"documentation\" for DDFacet (and similarly for killMS, to a much lesser degree) in their respective parset.cfg file. For DDF, look here:\n",
    "\n",
    "https://github.com/saopicc/DDFacet/blob/master/DDFacet/Parset/DefaultParset.cfg\n",
    "\n",
    "\n",
    "Should you want a slightly more convenient install, Martin Hardcastle's DDF-pipeline installs both of the above for you:\n",
    "\n",
    "* https://github.com/mhardcastle/ddf-pipeline\n",
    "\n",
    "Let's start by taking a little look at the options of DDFacet. Run the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DDF.py -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there's quite a bit!...in fact, the vast majority of them can be safely ignored. For starters, let's make a small image with our dataset. Since I'm running this on my laptop, I don't want to use too many processors, nor make too large an image (the defaults for NCPU and NPix are 10 and 5000 respectively)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " DDF.py --Data-MS DATA/L242400_SB095_uv.dppp.4h-4.5h.MS --Parallel-NCPU 4 --Image-NPix 500 --Output-Mode Dirty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If all went well, you should now have a restored image of our 30min data. As you can see, the dirty image isn't much to look at (which is expected - 30min of supersynthesis leaves much to be desired in terms of uv-coverage!) and the restored image even worse. Indeed, we don't seem to have signal in our field. Let's try to shift to 3C295 to see what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-8ce18d386b62>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-8ce18d386b62>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    DDF.py --Data-MS DATA/L242400_SB095_uv.dppp.4h-4.5h.MS --Parallel-NCPU 4 --Image-NPix 500 --Output-Mode Dirty --Image-PhaseCenterRADEC=[\"14:11:20.23\",\"52:12:04.30\"]\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    " DDF.py --Data-MS DATA/L242400_SB095_uv.dppp.4h-4.5h.MS --Parallel-NCPU 4 --Image-NPix 500 --Output-Mode Dirty --Image-PhaseCenterRADEC=[\"14:11:20.23\",\"52:12:04.30\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're getting somewhere! Clearly we have a bright source in the middle. Time to clean it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " DDF.py --Data-MS DATA/L242400_SB095_uv.dppp.4h-4.5h.MS --Parallel-NCPU 4 --Image-NPix 500 --Output-Mode Clean --Image-PhaseCenterRADEC=[\"14:11:20.23\",\"52:12:04.30\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the default of --Output-Mode is actually Clean, so we don't need to put that in our command line, strictly speaking. Let's look at the output again - it should be a nice Gaussian blob! To see other things in the field, we need to subtract this source from our visibilities. To do this, we'll go back to NDPPP. Put the following in a parset called \"ndppp.subtract.parset\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msin  = DATA/L242400_SB095_uv.dppp.4h-4.5h.MS\n",
    "msout = DATA/L242400_SB095_uv.dppp.4h-4.5h.MS\n",
    "msin.datacolumn\t = CORRECTED_DATA\n",
    "msout.datacolumn = CORRECTED_DATA\n",
    "#msin.baseline=^CS*&  # ^ is the Not operator.\n",
    "msout.overwrite  = true\n",
    "\n",
    "# define the steps we use:\n",
    "# gaincal calibrates\n",
    "steps = [predict]\n",
    "\n",
    "predict.baseline       = [CR]*&&\n",
    "predict.sourcedb       = DATA/L242400_SB095_uv.dppp.4h-4.5h.MS/sky\n",
    "predict.operation      = subtract\n",
    "predict.usebeammodel   = true\n",
    "predict.beammode       = default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you can add \"predict\" to the steps of your first ndppp parset, specifying the parameters above. Now, we should have subtracted 3C295 from our visibilities - let's check!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " DDF.py --Data-MS DATA/L242400_SB095_uv.dppp.4h-4.5h.MS --Parallel-NCPU 4 --Image-NPix 500 --Output-Mode Dirty --Image-PhaseCenterRADEC=[\"14:11:20.23\",\"52:12:04.30\"] --Output-Name subtracted.image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All seems in order! Let's look at our target field again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " DDF.py --Data-MS DATA/L242400_SB095_uv.dppp.4h-4.5h.MS --Parallel-NCPU 4 --Image-NPix 500 --Output-Mode Clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see a few sources in the field - excellent news. To summarise, we have:\n",
    "\n",
    "- downloaded and opened a raw dataset\n",
    "- calibrated it with NDPPP\n",
    "- imaged it and saw we were dominated by a source in the field\n",
    "- subtracted said source from the field\n",
    "- achieved an image of our target field.\n",
    "\n",
    "Let's close by looking at the contents of a DDF parset. Each DDF run creates an associated parset. This is useful for two reasons: firstly, it means that you know exactly what your last run of a given name used as parameters. Second, it makes it very easy to duplicate results: you can run DDF in the command line by giving commands, but can also set all the defaults to be those of an input parset as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DDF.py whatever.parset --Output-Mode PSF --Image-NPix 2 ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the contents of our latest parset output, image.parset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[Data]\n",
    "MS = DATA/L242400_SB095_uv.dppp.4h-4.5h.MS \n",
    "ColName = CORRECTED_DATA \n",
    "ChunkHours = 0.0 \n",
    "Sort = False \n",
    "\n",
    "[Predict]\n",
    "ColName = None \n",
    "MaskSquare = None \n",
    "FromImage = None \n",
    "InitDicoModel = None \n",
    "Overwrite = True \n",
    "\n",
    "[Selection]\n",
    "Field = 0 \n",
    "DDID = 0 \n",
    "TaQL =  \n",
    "ChanStart = 0 \n",
    "ChanEnd = -1 \n",
    "ChanStep = 1 \n",
    "FlagAnts =  \n",
    "UVRangeKm = [0, 2000] \n",
    "TimeRange =  \n",
    "DistMaxToCore =  \n",
    "\n",
    "[Output]\n",
    "Mode = Clean \n",
    "Name = image \n",
    "ShiftFacetsFile = None \n",
    "RestoringBeam = None \n",
    "Also =  \n",
    "Cubes =  \n",
    "Images = DdPAMRIikz \n",
    "alphathreshold = 7 \n",
    "alphamaskthreshold = 15 \n",
    "StokesResidues = I \n",
    "\n",
    "[Image]\n",
    "NPix = 500 \n",
    "Cell = 5.0 \n",
    "PhaseCenterRADEC = align \n",
    "SidelobeSearchWindow = 200 \n",
    "\n",
    "[Facets]\n",
    "NFacets = 3 \n",
    "CatNodes = None \n",
    "DiamMax = 180.0 \n",
    "DiamMin = 0.0 \n",
    "PSFOversize = 1.0 \n",
    "PSFFacets = 0 \n",
    "Padding = 1.7 \n",
    "Circumcision = 0 \n",
    "\n",
    "[Weight]\n",
    "ColName = WEIGHT_SPECTRUM \n",
    "Mode = Briggs \n",
    "MFS = True \n",
    "Robust = 0.0 \n",
    "SuperUniform = 1.0 \n",
    "\n",
    "[RIME]\n",
    "Precision = S \n",
    "PolMode = I \n",
    "FFTMachine = FFTW \n",
    "ForwardMode = BDA-degrid \n",
    "BackwardMode = BDA-grid \n",
    "DecorrMode =  \n",
    "DecorrLocation = Edge \n",
    "\n",
    "[CF]\n",
    "OverS = 11 \n",
    "Support = 7 \n",
    "Nw = 100 \n",
    "wmax = 0.0 \n",
    "\n",
    "[Comp]\n",
    "GridDecorr = 0.02 \n",
    "GridFoV = Facet \n",
    "DegridDecorr = 0.02 \n",
    "DegridFoV = Facet \n",
    "Sparsification = 0 \n",
    "BDAMode = 1 \n",
    "BDAJones = 0 \n",
    "\n",
    "[Parallel]\n",
    "NCPU = 4 \n",
    "Affinity = 1 \n",
    "MainProcessAffinity = 0 \n",
    "\n",
    "[Cache]\n",
    "Reset = True \n",
    "SmoothBeam = auto \n",
    "Weight = auto \n",
    "PSF = auto \n",
    "Dirty = auto \n",
    "VisData = auto \n",
    "LastResidual = True \n",
    "Dir =  \n",
    "DirWisdomFFTW = ~/.fftw_wisdom \n",
    "ResetWisdom = False \n",
    "CF = True \n",
    "HMP = False \n",
    "\n",
    "[Beam]\n",
    "Model = None \n",
    "At = facet \n",
    "LOFARBeamMode = AE \n",
    "NBand = 0 \n",
    "CenterNorm = False \n",
    "Smooth = False \n",
    "SmoothNPix = 11 \n",
    "FITSFile = beam_$(corr)_$(reim).fits \n",
    "FITSFeed = None \n",
    "DtBeamMin = 5.0 \n",
    "FITSParAngleIncDeg = 5.0 \n",
    "FITSLAxis = -X \n",
    "FITSMAxis = Y \n",
    "FITSVerbosity = 0 \n",
    "\n",
    "[Freq]\n",
    "BandMHz = 0.0 \n",
    "DegridBandMHz = 0.0 \n",
    "NBand = 1 \n",
    "NDegridBand = 0 \n",
    "\n",
    "[DDESolutions]\n",
    "DDSols =  \n",
    "SolsDir = None \n",
    "GlobalNorm = None \n",
    "JonesNormList = AP \n",
    "JonesMode = Full \n",
    "DDModeGrid = AP \n",
    "DDModeDeGrid = AP \n",
    "ScaleAmpGrid = 0 \n",
    "ScaleAmpDeGrid = 0 \n",
    "CalibErr = 10.0 \n",
    "Type = Nearest \n",
    "Scale = 1.0 \n",
    "gamma = 4.0 \n",
    "RestoreSub = False \n",
    "ReWeightSNR = 0.0 \n",
    "\n",
    "[Deconv]\n",
    "Mode = HMP \n",
    "MaxMajorIter = 20 \n",
    "MaxMinorIter = 20000 \n",
    "AllowNegative = True \n",
    "Gain = 0.1 \n",
    "FluxThreshold = 0.0 \n",
    "CycleFactor = 0.0 \n",
    "RMSFactor = 0.0 \n",
    "PeakFactor = 0.15 \n",
    "PrevPeakFactor = 0.0 \n",
    "NumRMSSamples = 10000 \n",
    "ApproximatePSF = 0 \n",
    "PSFBox = auto \n",
    "\n",
    "[Mask]\n",
    "External = None \n",
    "Auto = False \n",
    "SigTh = 10 \n",
    "FluxImageType = ModelConv \n",
    "\n",
    "[Noise]\n",
    "MinStats = [60, 2] \n",
    "BrutalHMP = True \n",
    "\n",
    "[HMP]\n",
    "Alpha = [-1.0, 1.0, 11] \n",
    "Scales = [0] \n",
    "Ratios = [''] \n",
    "NTheta = 6 \n",
    "SolverMode = PI \n",
    "AllowResidIncrease = 0.1 \n",
    "MajorStallThreshold = 0.8 \n",
    "Taper = 0 \n",
    "Support = 0 \n",
    "PeakWeightImage = None \n",
    "Kappa = 0.0 \n",
    "OuterSpaceTh = 2.0 \n",
    "FractionRandomPeak = None \n",
    "\n",
    "[Hogbom]\n",
    "PolyFitOrder = 3 \n",
    "MaxLengthScale = 5 \n",
    "FreqMode = Poly \n",
    "NumBasisFuncs = 12 \n",
    "\n",
    "[Montblanc]\n",
    "TensorflowServerTarget =  \n",
    "\n",
    "[SSDClean]\n",
    "Parallel = True \n",
    "IslandDeconvMode = GA \n",
    "SSDSolvePars = ['S', 'Alpha'] \n",
    "SSDCostFunc = ['Chi2', 'MinFlux'] \n",
    "BICFactor = 0.0 \n",
    "ArtifactRobust = False \n",
    "ConvFFTSwitch = 1000 \n",
    "NEnlargePars = 0 \n",
    "NEnlargeData = 2 \n",
    "RestoreMetroSwitch = 0 \n",
    "MinMaxGroupDistance = [10, 50] \n",
    "\n",
    "[GAClean]\n",
    "NSourceKin = 50 \n",
    "NMaxGen = 50 \n",
    "MinSizeInit = 10 \n",
    "InitType = HMP \n",
    "AlphaInitHMP = [-4.0, 1.0, 6] \n",
    "ScalesInitHMP = [0, 1, 2, 4, 8, 16, 24, 32] \n",
    "GainInitHMP = 0.1 \n",
    "RatiosInitHMP = [''] \n",
    "NThetaInitHMP = 4 \n",
    "MaxMinorIterInitHMP = 10000 \n",
    "AllowNegativeInitHMP = False \n",
    "RMSFactorInitHMP = 3.0 \n",
    "ParallelInitHMP = True \n",
    "NCPU = 0 \n",
    "\n",
    "[MORESANE]\n",
    "NMajorIter = 200 \n",
    "NMinorIter = 200 \n",
    "Gain = 0.1 \n",
    "ForcePositive = True \n",
    "SigmaCutLevel = 1 \n",
    "\n",
    "[MUFFIN]\n",
    "mu_s = 0.1 \n",
    "mu_l = 0.2 \n",
    "nb = ['(8', '0)'] \n",
    "NMinorIter = 200 \n",
    "\n",
    "[Log]\n",
    "Memory = False \n",
    "Boring = False \n",
    "Append = False \n",
    "\n",
    "[Debug]\n",
    "PauseWorkers = False \n",
    "FacetPhaseShift = [0.0, 0.0] \n",
    "PrintMinorCycleRMS = False \n",
    "DumpCleanSolutions = 0 \n",
    "DumpCleanPostageStamps =  \n",
    "CleanStallThreshold = 0.0 \n",
    "MemoryGreedy = True \n",
    "APPVerbose = 0 \n",
    "Pdb = auto \n",
    "\n",
    "[Misc]\n",
    "RandomSeed = None \n",
    "ParsetVersion = 0.2 \n",
    "ConserveMemory = False "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, quite a lot of options...here are the ones you would likely be concerned with. Note that the general command line syntax for an option in the pattern\n",
    "[Category]\n",
    "Option = True\n",
    "\n",
    "is --Category-Option True   (the = sign is facultative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[Data]\n",
    "MS = DATA/L242400_SB095_uv.dppp.4h-4.5h.MS # name of your ms\n",
    "ColName = CORRECTED_DATA                   # name of column to image\n",
    "ChunkHours = 0.0                           # in case of memory error, set to 4, 2, 1...\n",
    "\n",
    "[Selection]\n",
    "FlagAnts =                                 # regular expression or strings for ants to flag\n",
    "UVRangeKm = [0, 2000]                      # self evident\n",
    "\n",
    "[Output]\n",
    "Mode = Clean                               # can also be Dirty or PSF\n",
    "Name = image                               # name of image you're making\n",
    "RestoringBeam = None                       # set to 4 times cell size by default\n",
    "Cubes =                                    # if you want freq. cubes. See -h\n",
    "Images = DdPAMRIikz                        # see DDF.py -h | grep Images \n",
    "\n",
    "[Image]\n",
    "NPix = 500                                 # number of pixels a side\n",
    "Cell = 5.0                                 # pixel size in arcsec\n",
    "PhaseCenterRADEC = align                   # where to put centre of image. If align, same as MS phase centre\n",
    "\n",
    "[Weight]\n",
    "ColName = WEIGHT_SPECTRUM                  # weight column to use\n",
    "Mode = Briggs                              # self evident but maybe you want to use uniform or something\n",
    "Robust = 0.0                               # see above\n",
    "\n",
    "[RIME]\n",
    "DecorrMode =                               # set to FT for wide fields of view. it's RIME magic.\n",
    "\n",
    "[Parallel]\n",
    "NCPU = 4                                   # number of CPUs used for parallelisation\n",
    "\n",
    "[Cache]\n",
    "Reset = True                               # good practice to set this to True when not changing image name.\n",
    "\n",
    "[Beam]\n",
    "Model = None                               # can be LOFAR\n",
    "LOFARBeamMode = AE                         # can be A or AE\n",
    "\n",
    "[Freq]\n",
    "NBand = 1                                  # use this when you want to make cubes: get as many freq. slices as NBand\n",
    "\n",
    "# after that, it's just clean options.\n",
    "\n",
    "[Deconv]\n",
    "Mode = HMP \n",
    "MaxMajorIter = 20 \n",
    "MaxMinorIter = 20000 \n",
    "AllowNegative = True \n",
    "Gain = 0.1 \n",
    "FluxThreshold = 0.0 \n",
    "CycleFactor = 0.0 \n",
    "RMSFactor = 0.0 \n",
    "PeakFactor = 0.15 \n",
    "PrevPeakFactor = 0.0 \n",
    "NumRMSSamples = 10000 \n",
    "ApproximatePSF = 0 \n",
    "PSFBox = auto \n",
    "\n",
    "[Mask]\n",
    "External = None \n",
    "Auto = False \n",
    "SigTh = 10 \n",
    "FluxImageType = ModelConv \n",
    "\n",
    "\n",
    "[HMP]\n",
    "Alpha = [-1.0, 1.0, 11] \n",
    "Scales = [0] \n",
    "Ratios = [''] \n",
    "NTheta = 6 \n",
    "SolverMode = PI \n",
    "AllowResidIncrease = 0.1 \n",
    "MajorStallThreshold = 0.8 \n",
    "Taper = 0 \n",
    "Support = 0 \n",
    "PeakWeightImage = None \n",
    "Kappa = 0.0 \n",
    "OuterSpaceTh = 2.0 \n",
    "FractionRandomPeak = None "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
